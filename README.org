#+TITLE: Classification of DNA Sequences
#+OPTIONS: ^:nil
Library for classifying DNA Sequences.

Written to classify sequences by taxonomy but easily adaptable for
other classification tasks.
* Modules
** =models=
Contains definitions of model architectures based on convolutional,
recurrent, and temporal convolutional neural networks as well as
scripts for pre-training and fine-tuning BERT models adapted for
protein-coding gene sequences and genomic sequences
** =preprocessing=
Contains utilities for sequence input, encoding and model input generation.
** =utils=
Contains various scripts for training and evaluating model
architectures as well as predicting data using these models.
* Usage
** Training models
*** Data preparation
Two modes exist for preparing raw DNA sequences for training
**** Individual sequence fastas (=gene=)
Each sequence is contained in a fasta file, additionally, a =json=
file containg all file-names and associated classes can speed up
preprocessing tremendously. A fixed directory structure is
requiered:
#+begin_example
[class_1]/
  [sequence_1.fa]
  [seuqence_2.fa]
  ...
  [sequence_n.fa]
[class_2]/
  ...
.../
[class_n]/
  ...
  [sequence_l.fa]
{files.json}
#+end_example

The =json=-files cotains a list of two lists with equal size, the
first list contains filepaths to the fasta files and the second list
the associated classes:
#+begin_src json
[["class_1/sequence1.fa", "class_1/sequence2.fa", ..., "class_n/sequence_l.fa"],
 ["class_1", "class_1", ..., "class_n"]]
#+end_src
**** single sequence =json=
This mode requires a fixed directory structure with one =json= file
per class, consisting of a simple list of sequences:
#+begin_example
[class_1]/
  [class_1]_fragments.json
[class_2]/
  [class_2]_fragments.json
.../
[class_n]/
  [class_n]_fragments.json
#+end_example

Example fragments file:
#+begin_src json
["ACGTACGTACGATCGA", "TACACTTTTTA", ..., "ATACTATCTATCTA"]
#+end_src
*** Training and testing models
All Scripts described here are implemented as CLIs; detailed usage
information can be optained via the =--help= flag.

For RNN, CNN and TCN models, the script [[file:utils/test_model.py]] is used:
#+begin_src shell
  python utils/test_model.py tcn --nr_seqs 10_000 --summary \
	 --root_fa_dir sequences --file_names_cache sequences/files.json
#+end_src

To pre-train BERT (gene) models (Script [[file:models/bert_pretrain.py]]):
#+begin_src shell
  python -m models.bert_pretrain bert_gene_C2 --epochs 10 --batch_size 32 --seq_len 502 \
	 --head_num 5 --embed_dim 250 --feed_forward_dim 1024 --dropout_rate 0.05 \
	 --root_fa_dir sequences --from_cache sequences/files.json
#+end_src

To fine-tune BERT (genomic) models (Script [[file:models/bert_finetune.py]])
#+begin_src shell
  python -m models.bert_finetune bert_gene_C2_trained.h5 --epochs 4 \
	 --root_fa_dir sequences --from_cache sequences/files.json
#+end_src

The scripts [[file:models/bert_nc.py]] and [[file:models/bert_nc_finetune.py]] are used
analogously, with the exception of sequence specification:

#+begin_src shell
  python -m models.bert_nc single_sequence_json_folder/
#+end_src

#+begin_src shell
  python -m models.bert_nc_finetune bert_nc_trained.h5 single_sequence_json_folder/
#+end_src
** Using BERT models

A script is available to predict sequences in using a BERT model.
For example, sequences contained in a fasta file can be predicted:

#+begin_src fasta
> class_1
ACGTAGCTA
> class_2
ACATATATTATATTTT
#+end_src

#+begin_src shell
python -m utils.test_bert finetuned_bert.h5 --fasta sequences.fa
#+end_src

For this script =--help= provides further usage information.
* Dependencies
- tensorflow >= 2
- keras
- numpy
- tqdm
- scikit-learn
- keras-bert
- keras-tcn
